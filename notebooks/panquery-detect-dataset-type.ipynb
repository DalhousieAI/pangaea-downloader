{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting the type of dataset before fetching it as a `PanDataSet`\n",
    "\n",
    "There are different types of datasets on Pangaea\n",
    "- Table format datasets (row x col) where we can easily check if it has the desired column\n",
    "- Seafloor videos which are usually too large to be fetched as a `PanDataSet`\n",
    "- Images hosted on the website\n",
    "\n",
    "In this Notebook we will attempt to detect the type of dataset before fetching it as a `PanDataSet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import pangaeapy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from downloader.utilz import fetch_child_datasets, has_url_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"seafloor video\"\n",
    "n_results = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pq = pangaeapy.PanQuery(query=query, limit=n_results)\n",
    "print(\"Requested URL:\", pq.PANGAEA_QUERY_URL + \"+\".join(pq.query.split(\" \")))\n",
    "\n",
    "print(\"Number of results returned:\", len(pq.result))\n",
    "print(\"Total search results\", pq.totalcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Processing a result item\n",
    "The dictionary returned for each result item has some useful information.\n",
    "\n",
    "- The `URI` can be used to fetch the `PanDataSet`\n",
    "\n",
    "- The `type` tells us if it has child datasets\n",
    "\n",
    "- Within the `html` we find a number of useful info\n",
    "    - The citation for the dataset\n",
    "    - The URL of the dataset webpage\n",
    "    - The dataset size (eg: \n",
    "        - 14 datasets (has child datasets)\n",
    "        - 500 data points (normal tabular format)\n",
    "        - 50 MBytes (video)\n",
    "        - unknown (images hosted on website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pq.result[0]\n",
    "print(\"Result dict keys:\", result.keys())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_result(result, verbose=False):\n",
    "    soup = BeautifulSoup(result[\"html\"])\n",
    "    citation = soup.find(\"div\", attrs={\"class\": \"citation\"}).text\n",
    "    url = soup.find(\"a\", attrs={\"class\": \"dataset-link\"})[\"href\"]\n",
    "    size = soup.find_all(\"td\", class_=\"content\")[-1].text\n",
    "    is_parent = True if result[\"type\"] == \"parent\" else False\n",
    "\n",
    "    if verbose:\n",
    "        print(citation, url)\n",
    "        print(\n",
    "            f\"Dataset size: {size}, Has child datasets: {is_parent}, TF-IDF Score: {result['score']}\"\n",
    "        )\n",
    "    return url, size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "from numpy.random import randint\n",
    "\n",
    "idx = randint(0, len(pq.result))\n",
    "url, size = process_result(pq.result[idx], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url, size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Viewing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(pq.result):\n",
    "    url, size = process_result(result)\n",
    "    if not \"data\" in size:  # Excluding datasets/data points\n",
    "        print(f\"[{i}]\", size, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in pq.result:\n",
    "    process_result(result, verbose=True)\n",
    "    print(\"-\" * 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (ws)",
   "language": "python",
   "name": "ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
