{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from pangaea_downloader import checker, eda, utilz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files from downloads directory\n",
    "TEST_DIR = \"../query-outputs/\"\n",
    "files = os.listdir(TEST_DIR)\n",
    "df_list = [pd.read_csv(os.path.join(TEST_DIR, f)) for f in files]\n",
    "print(f\"Total {len(df_list)} datasets loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Count images in each file\n",
    "- Count values in URL column\n",
    "- Number of valid URLs\n",
    "- Number of invalid URLs\n",
    "- URLs with image file extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_counts = []\n",
    "for i, (file, df) in enumerate(zip(files, df_list)):\n",
    "    # Count only the first url column\n",
    "    col = utilz.get_url_cols(df)[0]\n",
    "    # Count stuff\n",
    "    n_rows = len(df)\n",
    "    count = df[col].count()\n",
    "    valid_url = df[col].apply(checker.is_url).sum()\n",
    "    invalid_url = count - valid_url\n",
    "    valid_img_ext = df[col].apply(checker.is_img_url).sum()\n",
    "    missing = df[col].isna().sum()\n",
    "    # Keep record of counts\n",
    "    img_counts.append(\n",
    "        {\n",
    "            \"file\": file,\n",
    "            \"column\": col,\n",
    "            \"n_rows\": n_rows,\n",
    "            \"count\": count,\n",
    "            \"valid_url\": valid_url,\n",
    "            \"invalid_url\": invalid_url,\n",
    "            \"valid_img_ext\": valid_img_ext,\n",
    "            \"missing\": missing,\n",
    "        }\n",
    "    )\n",
    "# Make a dataframe\n",
    "img_counts = pd.DataFrame(img_counts)\n",
    "\n",
    "# Show resuts\n",
    "print(f\"Raw image count in all files: {img_counts['count'].sum()}\")\n",
    "print(f\"Total number of valid urls: {img_counts['valid_url'].sum()}\")\n",
    "print(f\"Total number of valid image urls: {img_counts['valid_img_ext'].sum()}\")\n",
    "img_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Campaigns\n",
    "- How many campaigns (Why 33 campaigns for 290+ files?)\n",
    "- Distribution of images across campaigns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Check if each file has only one campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets with more than one campaign (should be empty)\n",
    "a = [df[\"Campaign\"].unique() for df in df_list if df[\"Campaign\"].nunique() > 1]\n",
    "if not len(a) > 0:\n",
    "    print(\"Each files has one associated campaign.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Number of datasets per campaign\n",
    "Many of the datasets are from the same campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.DataFrame(\n",
    "    {\n",
    "        \"file\": files,\n",
    "        \"campaign\": [df[\"Campaign\"].unique()[0] for df in df_list],\n",
    "        \"total_nans\": [df.isna().sum().sum() for df in df_list],\n",
    "        \"nan_percent\": [round(df.isna().sum().sum() / df.size, 4) for df in df_list],\n",
    "    }\n",
    ")\n",
    "datasets.loc[35:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total datasets: {datasets['campaign'].count()}\")\n",
    "print(f\"Total number of campaigns in all files: {datasets['campaign'].nunique()}\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Number of datasets per campaign\")\n",
    "sns.countplot(data=datasets, y=\"campaign\", edgecolor=\"black\", linewidth=1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Number of images per campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camps = {campaign: 0 for campaign in datasets[\"campaign\"].unique()}\n",
    "for df in df_list:\n",
    "    campaign = df[\"Campaign\"].unique()[0]\n",
    "    img_cols = utilz.get_url_cols(df)\n",
    "    if len(img_cols) > 0:\n",
    "        img_col = img_cols[0]\n",
    "        camps[campaign] += df[img_col].count()\n",
    "camps = pd.Series(camps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Number of images per campaign\")\n",
    "sns.barplot(y=camps.index, x=camps.values, edgecolor=\"black\", linewidth=1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Site/deployment/event\n",
    "### 3.1 Number of sites per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_site_per_file = pd.DataFrame(\n",
    "    {\"file\": files, \"n_sites\": [df[\"Site\"].nunique() for df in df_list]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(16, 5))\n",
    "# Raw numbers\n",
    "ax[0].set_title(\"Number of sites in downloaded datasets\\n\")\n",
    "ax[0].hist(num_site_per_file.n_sites, bins=30, edgecolor=\"black\", linewidth=1)\n",
    "ax[0].set_xlabel(\"Number of sites\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[0].grid()\n",
    "# Log scale\n",
    "ax[1].set_title(\"Number of sites in downloaded datasets\\n(log scale)\")\n",
    "ax[1].hist(num_site_per_file.n_sites, bins=30, edgecolor=\"black\", linewidth=1)\n",
    "ax[1].set_xlabel(\"Number of sites\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Total number of unique sites:\",\n",
    ")\n",
    "print(len(num_site_per_file[num_site_per_file.n_sites == 1]))\n",
    "print(\"\\nDatasets/files with more than 1 site:\")\n",
    "num_site_per_file[num_site_per_file.n_sites > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most datasets have images from 1 site\n",
    "- A few datasets have images from several sites (shown in table above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Number of datasets per site/event/deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_datasets = []\n",
    "for i, (file, df) in enumerate(zip(files, df_list)):\n",
    "    for site in df[\"Site\"].unique():\n",
    "        site_datasets.append({\"file\": file, \"site\": site})\n",
    "site_datasets = pd.DataFrame(site_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total datasets: {len(df_list)}\")\n",
    "print(f\"Total number of sites in all files: {site_datasets['site'].nunique()}\")\n",
    "plt.figure(figsize=(5, 40))\n",
    "plt.title(\"Number of datasets from each site\")\n",
    "sns.countplot(data=site_datasets, y=\"site\", edgecolor=\"black\", linewidth=1)\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Number of images per site/event/deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_img_counts = {site: 0 for site in site_datasets.site.unique()}\n",
    "for df in df_list:\n",
    "    img_col = utilz.get_url_cols(df)[0]\n",
    "    for site in df[\"Site\"].unique():\n",
    "        site_img_counts[site] += df[df.Site == site][img_col].count()\n",
    "site_img_counts = pd.Series(site_img_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 45))\n",
    "plt.title(\"Number of images per site/deployment/event\")\n",
    "sns.barplot(\n",
    "    y=site_img_counts.index, x=site_img_counts.values, edgecolor=\"black\", linewidth=1\n",
    ")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(45, 8))\n",
    "plt.title(\"Number of images per site/deployment/event\", fontsize=35)\n",
    "sns.barplot(\n",
    "    x=site_img_counts.index, y=site_img_counts.values, edgecolor=\"black\", linewidth=1\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(fontsize=30)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze missing values\n",
    "- Raw total missing values\n",
    "- How many missing values in mandatory columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 How many datasets have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 5))\n",
    "fig.suptitle(\"Missing values across datasets\")\n",
    "ax[0].hist(datasets[\"total_nans\"], bins=20, edgecolor=\"black\", linewidth=1)\n",
    "ax[0].set_xlabel(\"Number of missing values\")\n",
    "ax[0].set_ylabel(\"Count\")\n",
    "ax[0].grid()\n",
    "# ax[0].set_yscale(\"log\")\n",
    "ax[1].hist(datasets[\"nan_percent\"], bins=20, edgecolor=\"black\", linewidth=1)\n",
    "ax[1].set_xlabel(\"Percentage of missing values\")\n",
    "ax[1].set_ylabel(\"Count\")\n",
    "ax[1].grid()\n",
    "# ax[1].set_yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see most datasets have close to 0 missing values. There are a few datasets with 5,000 or close to 40,000 missing values. The percentage plot also shows a similar picture. Most datasets have below 10% missing values. While a few have 20-25% missing. Percentages are calcualted by dividing the total number of missing values of a dataset and dividing by the size (rowsXcols) of then dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Detailed breakdown of missing values\n",
    "Let us now examine each dataset and check which columns have how many missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (df, file) in enumerate(zip(df_list, files)):\n",
    "    nans_per_column = df.isna().sum()\n",
    "    total_nans = nans_per_column.sum()\n",
    "    if total_nans > 0:\n",
    "        print(f\"[{i}][{file}] Total {total_nans} null values in dataframe.\")\n",
    "        display(nans_per_column[nans_per_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spatial distribution of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all data\n",
    "all_dfs = pd.concat(df_list)\n",
    "\n",
    "# Values for plotting\n",
    "x = all_dfs[\"Longitude\"].dropna().to_numpy()\n",
    "y = all_dfs[\"Latitude\"].dropna().to_numpy()\n",
    "print(\"x.shape:\", x.shape, \"y.shape:\", y.shape)\n",
    "\n",
    "# Projection\n",
    "projection = ccrs.EqualEarth()\n",
    "# Transform\n",
    "transform = ccrs.Geodetic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare map\n",
    "fig = plt.figure(figsize=(25, 8))\n",
    "ax = fig.add_subplot(projection=projection)\n",
    "ax.stock_img()\n",
    "\n",
    "# Plot data\n",
    "ax.scatter(x, y, color=\"r\", alpha=0.15, transform=transform)\n",
    "ax.set_title(\"Spatial distribution of image samples\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Kernal Density Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transparent colormap for plotting kernel density\n",
    "my_cmap = eda.make_transparent_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 KDE on a sample of all coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KDE\n",
    "X2_, Y2_, Z2_ = eda.kde_sklearn(x[::100], y[::100], metric=\"haversine\", bw_factor=0.1)\n",
    "\n",
    "# Grid scatter\n",
    "fig = plt.figure(figsize=(25, 8))\n",
    "ax = fig.add_subplot(projection=projection)\n",
    "ax.stock_img()\n",
    "ax.scatter(\n",
    "    np.degrees(X2_),\n",
    "    np.degrees(Y2_),\n",
    "    color=\"r\",\n",
    "    s=Z2_,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "ax.set_title(\"KDE of image sample spatial distribution (grid scatter)\")\n",
    "plt.show()\n",
    "\n",
    "# Contour plot (KDE)\n",
    "fig = plt.figure(figsize=(25, 8))\n",
    "ax = fig.add_subplot(projection=projection)\n",
    "ax.stock_img()\n",
    "ax.contourf(\n",
    "    np.degrees(X2_),\n",
    "    np.degrees(Y2_),\n",
    "    np.exp(Z2_),\n",
    "    cmap=my_cmap,\n",
    "    # extent=[x0, x1, y0, y1],\n",
    "    levels=np.linspace(0, np.exp(Z2_.max()), 25),\n",
    "    # origin='lower',\n",
    "    # transform=transform,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    # transform=ccrs.RotatedPole(),\n",
    ")\n",
    "# ax.scatter(x, y, color='r', alpha=0.25, transform=transform)\n",
    "ax.set_title(\"KDE of image sample spatial distribution (densities)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 KDE on all coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform KDE\n",
    "X2_, Y2_, Z2_ = eda.kde_sklearn(x, y, metric=\"haversine\", bw_factor=0.5)\n",
    "\n",
    "# Grid scatter\n",
    "fig = plt.figure(figsize=(25, 8))\n",
    "ax = fig.add_subplot(projection=projection)\n",
    "ax.stock_img()\n",
    "ax.scatter(\n",
    "    np.degrees(X2_),\n",
    "    np.degrees(Y2_),\n",
    "    color=\"r\",\n",
    "    s=Z2_,\n",
    "    transform=ccrs.PlateCarree(),\n",
    ")\n",
    "ax.set_title(\"KDE of image sample spatial distribution (grid scatter)\")\n",
    "plt.show()\n",
    "\n",
    "# Contour plot (KDE)\n",
    "fig = plt.figure(figsize=(25, 8))\n",
    "ax = fig.add_subplot(projection=projection)\n",
    "ax.stock_img()\n",
    "ax.contourf(\n",
    "    np.degrees(X2_),\n",
    "    np.degrees(Y2_),\n",
    "    np.exp(Z2_),\n",
    "    cmap=my_cmap,\n",
    "    # extent=[x0, x1, y0, y1],\n",
    "    levels=np.linspace(0, np.exp(Z2_.max()), 25),\n",
    "    # origin='lower',\n",
    "    # transform=transform,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    # transform=ccrs.RotatedPole(),\n",
    ")\n",
    "# ax.scatter(x, y, color='r', alpha=0.25, transform=transform)\n",
    "ax.set_title(\"KDE of image sample spatial distribution (densities)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plot Sample images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Take a sample of image urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample each file/dataset's url column\n",
    "sample_imgs = []\n",
    "for i, (file, df) in enumerate(zip(files, df_list)):\n",
    "    # Take a sample from the first url column\n",
    "    col = utilz.get_url_cols(df)[0]\n",
    "    sample = df[col].sample().iloc[0]\n",
    "    # Check if it is string and is valid url\n",
    "    if (\n",
    "        isinstance(sample, str)\n",
    "        and checker.is_url(sample)\n",
    "        and (sample.lower().endswith(checker.VALID_IMG_EXTENSIONS))\n",
    "    ):\n",
    "        sample_imgs.append(sample)\n",
    "\n",
    "# Keep a subset of samples\n",
    "sample_imgs = np.random.choice(sample_imgs, size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Retrieve sampled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add function to utilz.py\n",
    "def img_from_url(url: str, verbose=False) -> np.array:\n",
    "    \"\"\"Take an image url and return retrieved image array.\"\"\"\n",
    "    success = False\n",
    "    while not success:\n",
    "        resp = requests.get(url, stream=True)\n",
    "        print(f\"status code: {resp.status_code}\") if verbose else 0\n",
    "        success = True if (resp.status_code == 200) else False\n",
    "        if success:\n",
    "            arr = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "            img = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Plot sampled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 4\n",
    "nrows = int(len(sample_imgs) / ncols)\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, nrows * 4))\n",
    "for ax, url in zip(axes.flat, sample_imgs):\n",
    "    print(f\"Retrieving: {url} ...\")\n",
    "    img = img_from_url(url, verbose=True)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"Shape: {img.shape}\")\n",
    "fig.tight_layout()\n",
    "fig.set_facecolor(\"w\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (ws)",
   "language": "python",
   "name": "ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
