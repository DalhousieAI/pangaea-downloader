{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e57110e",
   "metadata": {},
   "source": [
    "# Dataset details scraper\n",
    "**Input:** Pangaea benthic image dataset csv file.\n",
    "\n",
    "**Output:**\n",
    "- `.csv` file with:\n",
    "    - \"id\" (the 6 digit pangaea dataset ID)\n",
    "    - \"license\" (the license code)\n",
    "    - \"license_url\" (the url to the full license text)\n",
    "    - \"citation_paper\" (plain text citation for the paper)\n",
    "    - \"proj_name\" (the name of the project the dataset is part of)\n",
    "    - \"proj_url\" (url to the project website/wiki etc.)\n",
    "\n",
    "- `.bib` file with all the bibtex citations for each dataset\n",
    "\n",
    "- `.tex` file with Latex table for Table 2 of the BenthicNet Dataset Paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a3eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gem install anystyle-cli\n",
    "! anystyle --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "import pangaeapy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from pangaea_downloader.tools.checker import is_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164bb1f",
   "metadata": {},
   "source": [
    "## 1. Load Pangaea Benthic Image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d08b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pangaea_file = \"../full-dataset/pangaea_2022-03-03_filtered_no-repeats_sorted-first_subsampled-1.25m-40b-200-40m_100-200m_fewfact2-nonspa-exh2.csv\"\n",
    "pangaea_file = \"../full-dataset/pangaea_2022-01-24_filtered.csv\"\n",
    "# pangaea_file = \"../full-dataset/pangaea_2022-01-24.csv\"\n",
    "df = pd.read_csv(pangaea_file, low_memory=False)\n",
    "sorted_ids = sorted([int(ds_id.split(\"-\")[-1]) for ds_id in df.dataset.unique()])\n",
    "ds_ids = [f\"pangaea-{id_}\" for id_ in sorted_ids]\n",
    "print(f\"Total {len(ds_ids)} dataset licenses to fetch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674b381a",
   "metadata": {},
   "source": [
    "## 2. Scrape dataset details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea068d31",
   "metadata": {},
   "source": [
    "### 2.1 Functions to extract dataset metadata\n",
    "- Dataset citation (BibTex)\n",
    "- Paper citation (Plain text)\n",
    "- Project URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_url(ds_id: Union[str, int]) -> str:\n",
    "    \"\"\"Return dataset URL given six digit dataset ID.\"\"\"\n",
    "    if isinstance(ds_id, int):\n",
    "        ds_id = str(ds_id)\n",
    "    if ds_id.startswith(\"pangaea\"):\n",
    "        ds_id = ds_id.split(\"-\")[-1]\n",
    "    return f\"https://doi.pangaea.de/10.1594/PANGAEA.{ds_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80170fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bibtex(ds_id: str, verbose=False) -> str:\n",
    "    \"\"\"Get the BibTex Citation of a Pangaea dataset using the dataset ID.\"\"\"\n",
    "    bib_url = get_dataset_url(ds_id) + \"?format=citation_bibtex\"\n",
    "    resp = requests.get(bib_url)\n",
    "    if verbose:\n",
    "        print(\"\\tStatus code:\", resp.status_code)\n",
    "    return resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1046701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_tag(soup: BeautifulSoup, field: str) -> Tag:\n",
    "    \"\"\"\n",
    "    Find and return the div tag of class=\"row\" containing the given data field.\n",
    "\n",
    "    Paramaters\n",
    "    ----------\n",
    "    soup: bs4.BeautifulSoup\n",
    "        The parsed html to search within.\n",
    "    field: str\n",
    "        The fields to the left of each Pangaea dataset webpage.\n",
    "        Possible values: [\"citation\", \"project\", \"license\", \"size\" etc.]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    row: bs4.element.Tag\n",
    "        the div tag containing the information relating to the given field.\n",
    "    \"\"\"\n",
    "    for div in soup.find_all(\"div\", class_=\"title\"):\n",
    "        if not field.lower() in div.text.lower():\n",
    "            continue\n",
    "        row = div.parent.parent\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9475ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_citation(soup: BeautifulSoup) -> Optional[str]:\n",
    "    \"\"\"Given a parsed html object return the dataset research paper citation.\"\"\"\n",
    "    row = get_info_tag(soup, \"citation\")\n",
    "    if row is None:\n",
    "        return\n",
    "    word = \"Supplement to:\"\n",
    "    for line in row.find(\"h1\", class_=\"hanging citation\").text.split(\"\\n\"):\n",
    "        if word.lower() in line.lower():\n",
    "            citation = line.split(word)[-1].strip().replace(word, \"\")\n",
    "            citation = citation.replace(\"In supplement to: \", \"\")\n",
    "            return citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91984e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_project_info(ds: pangaeapy.PanDataSet, soup: BeautifulSoup):\n",
    "    \"\"\"Given a parsed html object return a tuple with the dataset project name and URL (if available).\"\"\"\n",
    "    name, url = None, None\n",
    "    if len(ds.projects) > 0:\n",
    "        name = ds.projects[0].name.text if ds.projects[0].name is not None else None\n",
    "        href = ds.projects[0].URL.text if ds.projects[0].URL is not None else None\n",
    "        if isinstance(href, str) and is_url(href):\n",
    "            url = href\n",
    "        return name, url\n",
    "\n",
    "    proj = get_info_tag(soup, \"Project\")\n",
    "    if proj is not None:\n",
    "        name = proj.find(\"div\", class_=\"descr\").text.strip()\n",
    "        pop_link = proj.find(\"a\", class_=\"popover-link\")\n",
    "        if pop_link is not None:\n",
    "            try:\n",
    "                href_tag = pop_link[\"data-content\"].split(\"\\n\")[1].split(\" \")[4]\n",
    "                href = href_tag.split('\"')[1]\n",
    "            except IndexError:\n",
    "                href = None\n",
    "    return name, url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e605414",
   "metadata": {},
   "source": [
    "### 2.2 Scrape information for one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_id = 198643\n",
    "ds_id = f\"pangaea-{ds_id}\"\n",
    "ds_url = get_dataset_url(ds_id)\n",
    "print(ds_url)\n",
    "\n",
    "resp = requests.get(ds_url)\n",
    "print(\"Status_code:\", resp.status_code)\n",
    "soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "bibtex = get_bibtex(ds_id)\n",
    "bib_tag = bibtex.split(\"{\")[1].split(\",\")[0]\n",
    "bibtex = bibtex.replace(bib_tag, ds_id)\n",
    "print(bibtex)\n",
    "print(bib_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7150fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pangaeapy.PanDataSet(ds_url, include_data=False)\n",
    "assert ds is not None\n",
    "# Extract and store dataset info in dict\n",
    "info = {\n",
    "    \"dataset\": ds_id,\n",
    "    \"bibtex_tag\": bib_tag,\n",
    "    \"citation_dataset\": ds.citation,\n",
    "    \"parent\": None,\n",
    "    \"is_parent\": False,\n",
    "    \"children\": [],\n",
    "    \"license\": None,\n",
    "    \"license_url\": None,\n",
    "}\n",
    "# Parent dataset\n",
    "if len(ds.children) > 0:\n",
    "    children = [f\"pangaea-{child.split('.')[-1]}\" for child in ds.children]\n",
    "    info[\"is_parent\"] = True\n",
    "    info[\"children\"] = children\n",
    "# Child: Identify parents\n",
    "if \"In:\" in info[\"citation_dataset\"]:\n",
    "    info[\"parent\"] = f\"pangaea-{info['citation_dataset'].split('.')[-1]}\"\n",
    "info[\"citation_paper\"] = get_paper_citation(soup)\n",
    "if (ds.error != \"Data set is protected\") and (len(ds.licenses) > 0):\n",
    "    info[\"license\"] = ds.licenses[0].label.text\n",
    "    info[\"license_url\"] = ds.licenses[0].URI.text\n",
    "elif ds.error == \"Data set is protected\":\n",
    "    info[\"license\"] = \"Protected (License Unknown)\"\n",
    "    info[\"license_url\"] = None\n",
    "proj = get_project_info(ds, soup)\n",
    "info[\"proj_name\"], info[\"proj_url\"] = proj if proj is not None else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ecf400",
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc139b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_citation_paper(citation: str, ds: pangaeapy.PanDataSet) -> str:\n",
    "    \"\"\"Replace 'author et al.' in input string with full author list.\"\"\"\n",
    "    if \"et al.\" in citation:\n",
    "        authors = [f\"{auth.lastname}, {auth.firstname[0]}.\" for auth in ds.authors]\n",
    "        auth_str = \", \".join(authors[:-1]) + f\", and {authors[-1]}\"\n",
    "        corrected = auth_str + citation.split(\"et al.\")[-1]\n",
    "        return corrected\n",
    "    return citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca402498",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(info[\"citation_paper\"], str):\n",
    "    print(\"Original:\", info[\"citation_paper\"])\n",
    "    print()\n",
    "    print(\"Corrected:\", correct_citation_paper(info[\"citation_paper\"], ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d6e9a",
   "metadata": {},
   "source": [
    "### 2.3 For all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "bibtex_list = []\n",
    "info_list = []\n",
    "parent_child_mappings = {}\n",
    "\n",
    "errors = []\n",
    "for i, ds_id in enumerate(tqdm(ds_ids)):\n",
    "    try:\n",
    "        time.sleep(0.005)\n",
    "        # Produce the dataset URL from the ID\n",
    "        ds_url = get_dataset_url(ds_id)\n",
    "        print(f\"[{i+1}/{len(ds_ids)}] Requesting: {ds_url}\")\n",
    "\n",
    "        # Fetch the PanDataSet object\n",
    "        ds = pangaeapy.PanDataSet(ds_url, include_data=False)\n",
    "        assert ds is not None\n",
    "\n",
    "        # Request the dataset webpage and parse\n",
    "        resp = requests.get(ds_url)\n",
    "        while resp.status_code != 200:\n",
    "            print(f\"[ERROR] Status code: {resp.status_code}! Retrying...\")\n",
    "            time.sleep(0.0025)\n",
    "            resp = requests.get(ds_url)\n",
    "        soup = BeautifulSoup(resp.text, \"lxml\")\n",
    "\n",
    "        # Fetch the bibtex citation for the dataset\n",
    "        bibtex = get_bibtex(ds_id)\n",
    "        bib_tag = bibtex.split(\"{\")[1].split(\",\")[0]\n",
    "        bibtex = bibtex.replace(bib_tag, ds_id)\n",
    "\n",
    "        # Extract and store dataset info in dict\n",
    "        info = {\n",
    "            \"dataset\": ds_id,\n",
    "            \"bibtex_tag\": bib_tag,\n",
    "            \"citation_dataset\": ds.citation,\n",
    "            \"parent\": None,\n",
    "            \"is_parent\": False,\n",
    "            \"children\": [],\n",
    "            \"license\": None,\n",
    "            \"license_url\": None,\n",
    "        }\n",
    "        if len(ds.children) > 0:  # Parent dataset\n",
    "            children = [f\"pangaea-{child.split('.')[-1]}\" for child in ds.children]\n",
    "            parent_child_mappings[ds_id] = children\n",
    "            info[\"is_parent\"] = True\n",
    "            info[\"children\"] = children\n",
    "        # Child: Identify parents\n",
    "        if \"In:\" in info[\"citation_dataset\"]:\n",
    "            info[\"parent\"] = f\"pangaea-{info['citation_dataset'].split('.')[-1]}\"\n",
    "        info[\"citation_paper\"] = get_paper_citation(soup)\n",
    "        if isinstance(info[\"citation_paper\"], str):\n",
    "            info[\"citation_paper\"] = correct_citation_paper(info[\"citation_paper\"], ds)\n",
    "        if (ds.error != \"Data set is protected\") and (len(ds.licenses) > 0):\n",
    "            info[\"license\"] = ds.licenses[0].label.text\n",
    "            info[\"license_url\"] = ds.licenses[0].URI.text\n",
    "        elif ds.error == \"Data set is protected\":\n",
    "            info[\"license\"] = \"Protected (License Unknown)\"\n",
    "            info[\"license_url\"] = None\n",
    "        proj = get_project_info(ds, soup)\n",
    "        info[\"proj_name\"], info[\"proj_url\"] = proj if proj is not None else (None, None)\n",
    "\n",
    "        # Add info to list\n",
    "        bibtex_list.append(bibtex)\n",
    "        info_list.append(info)\n",
    "    except Exception as e:\n",
    "        print(\"[ERROR]\", e)\n",
    "        errors.append({\"dataset\": ds_id, \"error\": e})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d52730",
   "metadata": {},
   "source": [
    "## 3. Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c413e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../dataset_details/\"\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7262f",
   "metadata": {},
   "source": [
    "### Error logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef80423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save errors\n",
    "if len(errors) > 0:\n",
    "    error_logs = os.path.join(out_dir, f\"errors_{dt.date.today()}.csv\")\n",
    "    err_df = pd.DataFrame(errors)\n",
    "    err_df.to_csv(error_logs)\n",
    "    print(f\"[INFO] Error logs saved to: {error_logs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5225b",
   "metadata": {},
   "source": [
    "Check datasets that raised errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "if len(errors) > 0:\n",
    "    err = errors[idx]\n",
    "    print(err)\n",
    "    ds_id = err[\"dataset\"]\n",
    "    ds_url = get_dataset_url(ds_id)\n",
    "    print(ds_url)\n",
    "    ds = pangaeapy.PanDataSet(ds_url)\n",
    "\n",
    "    resp = requests.get(ds_url)\n",
    "    print(\"Status_code:\", resp.status_code)\n",
    "    soup = BeautifulSoup(resp.text, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaf7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue: many datasets have > 1 project\n",
    "for i, proj in enumerate(ds.projects):\n",
    "    print(f\"[{i}] {proj.name.text}\")\n",
    "    print(f\" URL: {proj.URL}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae116d94",
   "metadata": {},
   "source": [
    "### 3.1 `.csv`file: dataset details/metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = pd.DataFrame(info_list)\n",
    "output_file = os.path.join(out_dir, f\"pangaea-dataset-details_{dt.date.today()}.csv\")\n",
    "info_df.to_csv(output_file, index=False)\n",
    "print(f\"[INFO] All {len(info_df)} dataset details written to file: '{output_file}'\")\n",
    "info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022bec6",
   "metadata": {},
   "source": [
    "#### 3.1.1 Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aec74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4cfcc4",
   "metadata": {},
   "source": [
    "#### 3.1.2 License types and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf7f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df.fillna(\"NaN\").license.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53155c87",
   "metadata": {},
   "source": [
    "### 3.2 `.bib`file: dataset bibtex citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write citations to file\n",
    "bibtex_file = os.path.join(out_dir, f\"pangaea-datasets_{dt.date.today()}.bib\")\n",
    "with open(bibtex_file, \"w\") as f:\n",
    "    f.writelines(bibtex_list)\n",
    "print(\n",
    "    f\"[INFO] All {len(bibtex_list)} dataset BibTex citations written to file: '{bibtex_file}'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bib in bibtex_list:\n",
    "    print(bib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e71b0",
   "metadata": {},
   "source": [
    "### 3.3 `.txt` file: plain text research paper citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd88465",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_citations_file = \"../dataset_details/pangaea-refs.txt\"\n",
    "paper_citations = info_df.citation_paper.dropna().unique()\n",
    "with open(text_citations_file, \"w\", encoding=\"UTF-8\") as f:\n",
    "    for i, citation in enumerate(paper_citations):\n",
    "        f.write(citation + \"\\n\")\n",
    "print(\n",
    "    f\"[INFO] All {len(paper_citations)} dataset research paper citations written to file: '{text_citations_file}'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3fba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat \"../dataset_details/pangaea-refs.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807648d1",
   "metadata": {},
   "source": [
    "### 3.4 Convert plain text research paper citations to bibtex and save to `.bib` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to bibtex\n",
    "command = \"anystyle\"\n",
    "txt_file = \"../dataset_details/pangaea-refs.txt\"\n",
    "args = [\"-f\", \"bib\", \"parse\", txt_file]\n",
    "ret = subprocess.run([command, *args], shell=True, capture_output=True)\n",
    "out = ret.stdout.decode(\"utf-8\").replace(\"\\r\", \"\").replace(\"date =\", \"year =\")\n",
    "paper_bibtex_list = [\"@\" + bib for bib in out.split(\"@\")][1:]\n",
    "\n",
    "# Write to file\n",
    "bib_file = \"../dataset_details/pangaea-refs.bib\"\n",
    "with open(bib_file, \"w\", encoding=\"UTF-8\") as f:\n",
    "    f.writelines(paper_bibtex_list)\n",
    "print(\n",
    "    f\"[INFO] All {len(paper_bibtex_list)} dataset research paper BibTex citations written to file: '{bib_file}'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93673ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat \"../dataset_details/pangaea-refs.bib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of BibTex tags for each plain text citation\n",
    "paper_bib_mappings = {}\n",
    "for text, bib in zip(paper_citations, paper_bibtex_list):\n",
    "    bib_tag = bib.split(\"{\")[1].split(\",\")[0]\n",
    "    paper_bib_mappings[bib_tag] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace plain text citations with paper BibTex citation tags\n",
    "for info in info_list:\n",
    "    if info[\"citation_paper\"] is not None:\n",
    "        for bib_tag, text in paper_bib_mappings.items():\n",
    "            if text == info[\"citation_paper\"]:\n",
    "                info[\"citation_paper_tag\"] = bib_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa0fbc",
   "metadata": {},
   "source": [
    "### 3.5 Dataset details latex table\n",
    "###### Table columns:\n",
    "- Dataset (pangaea ID)\n",
    "- Repository\n",
    "- NoSites\n",
    "- NoImages\n",
    "- License\n",
    "- Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = r\"\"\"\\begin{table}[tbhp]\n",
    "  \\centering\n",
    "  \\caption{\n",
    "Dataset details.\n",
    "}\n",
    "\\label{tab:datasets-appendix}\n",
    "\\centerline{\n",
    "\\begin{tabular}{llrrll}\n",
    "\\toprule\n",
    "Dataset & Repository & \\textnumero{} Sites & \\textnumero{} Images & License & Citations \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Generate latex table row entries\n",
    "rows = []\n",
    "for info in info_list:\n",
    "    ds_id = info[\"dataset\"]\n",
    "    # License info\n",
    "    license = \"License Missing!\".upper()\n",
    "    if info[\"license\"] is not None:\n",
    "        license = info[\"license\"]\n",
    "    if info[\"license_url\"] is not None:\n",
    "        license = r\"\\href{\" + info[\"license_url\"] + \"}\" \"{\" + info[\"license\"] + \"}\"\n",
    "    # Citation info\n",
    "    citations = r\"\\citet{\" + info[\"dataset\"] + \"}\"\n",
    "    if info[\"citation_paper\"] is not None:\n",
    "        citations = r\"\\citet{\" + f'{info[\"dataset\"]},{info[\"citation_paper_tag\"]}' + \"}\"\n",
    "    row = \"{} & PANGAEA & x & y & {} & {} \\\\\\\\ \\n\".format(ds_id, license, citations)\n",
    "    rows.append(row)\n",
    "\n",
    "bot = r\"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "}\n",
    "\\end{table}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42383a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write table to tex file\n",
    "tex_path = os.path.join(out_dir, f\"table_2-dataset-details_{dt.date.today()}.tex\")\n",
    "with open(tex_path, \"w\") as f:\n",
    "    f.write(top)\n",
    "    f.writelines(rows)\n",
    "    f.write(bot)\n",
    "print(f\"All {len(rows)} rows written to {tex_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c88ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top, end=\"\")\n",
    "for row in rows:\n",
    "    print(row, end=\"\")\n",
    "print(bot, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cb828",
   "metadata": {},
   "source": [
    "## 4. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf55dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in info_list:\n",
    "    for key in info.keys():\n",
    "        if not isinstance(info[key], str):\n",
    "            continue\n",
    "        if info[key].startswith(\"<!DOCTYPE html>\"):\n",
    "            print(info[\"dataset\"], key, info[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8ddb9",
   "metadata": {},
   "source": [
    "### 4.1 Check year field for dataset bibtex citaions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fdc56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"All {len(bibtex_list)} dataset BibTex citations have \"year\" field:\"\"\",\n",
    "    all([\"year={\" in bib for bib in bibtex_list]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc248251",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"\"\"All {len(paper_bibtex_list)} paper BibTex citations have \"year\" field:\"\"\",\n",
    "    all([\"year = {\" in bib for bib in paper_bibtex_list]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be46de",
   "metadata": {},
   "source": [
    "### 4.2 HTML instead of bibtex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61def7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_faulty = 0\n",
    "for bib in bibtex_list:\n",
    "    if bib.startswith(\"<!DOCTYPE html>\"):\n",
    "        n_faulty += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb73aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of datasets with html instead of bibtex:\", n_faulty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18e338",
   "metadata": {},
   "source": [
    "### 4.3 Check URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec6bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the license and project URLs are valid\n",
    "license_url_is_valid = info_df.license_url.dropna().apply(is_url).all()\n",
    "proj_url_is_valid = info_df.proj_url.dropna().apply(is_url).all()\n",
    "print(\"All URLs are valid:\")\n",
    "print(\"-------------------\")\n",
    "print(\"license_url:\\t\", license_url_is_valid)\n",
    "print(\"proj_url:\\t\", proj_url_is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26258c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show invalid license URLs\n",
    "if not license_url_is_valid:\n",
    "    for idx, url in (\n",
    "        info_df[~info_df.license_url.apply(is_url)].license_url.dropna().items\n",
    "    ):\n",
    "        dataset = info_df.loc[idx, \"dataset\"]\n",
    "        print(\n",
    "            f\"Dataset: {dataset}, License URL: {url}\\nDataset URL: {get_dataset_url(dataset)}\"\n",
    "        )\n",
    "        print(\"-\" * 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show invalid project URLs\n",
    "if not proj_url_is_valid:\n",
    "    dds = []\n",
    "    for idx, url in info_df[~info_df.proj_url.apply(is_url)].proj_url.dropna().items():\n",
    "        dataset = info_df.loc[idx, \"dataset\"]\n",
    "        print(\n",
    "            f\"Dataset: {dataset}, Project URL: {url}\\nDataset URL: {get_dataset_url(dataset)}\"\n",
    "        )\n",
    "        print(\"-\" * 85)\n",
    "        dds.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b245cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8441957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ed3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (ws)",
   "language": "python",
   "name": "ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
