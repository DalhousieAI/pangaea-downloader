{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab3f23-0a3d-4df4-abb6-20f61fe0cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from typing import Union\n",
    "\n",
    "import dateutil.parser\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from benthicnet.utils import sanitize_filename, sanitize_filename_series\n",
    "from IPython.display import display\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from pangaea_downloader.tools import checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35131f3-6be1-4db6-bd98-1517d62cf85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"../query-outputs_2022-01-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f2898-25da-4cea-99fa-3aa74a4f4e3e",
   "metadata": {},
   "source": [
    "## Load datasets and check distribution of column frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a01304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_url(ds_id: Union[str, int]) -> str:\n",
    "    \"\"\"Return dataset URL given six digit dataset ID.\"\"\"\n",
    "    if isinstance(ds_id, int):\n",
    "        ds_id = str(ds_id)\n",
    "    if ds_id.startswith(\"pangaea\"):\n",
    "        ds_id = ds_id.split(\"-\")[-1]\n",
    "    return f\"https://doi.pangaea.de/10.1594/PANGAEA.{ds_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29e38b1-f7e7-4e9e-a55f-7a9ac6adf706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url_column(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Find and return column with image URLs.\"\"\"\n",
    "    # Standardize column names\n",
    "    clean_cols = [\n",
    "        col.lower().replace(\" \", \"\").replace(\"-\", \"\").replace(\"_\", \"\").replace(\".\", \"\")\n",
    "        for col in df.columns\n",
    "    ]\n",
    "    # Ordered list of priorities\n",
    "    # Exclude url meta/ref/source which are not links to images\n",
    "    candidates = [\n",
    "        \"urlimage\",\n",
    "        \"urlraw\",\n",
    "        \"urlfile\",\n",
    "        \"url\",\n",
    "        \"urlgraphic\",\n",
    "        \"urlthumb\",\n",
    "        \"urlthumbnail\",\n",
    "        \"image\",\n",
    "        \"imagery\",\n",
    "    ]\n",
    "    # Find and return the first match\n",
    "    for candidate in candidates:\n",
    "        if candidate not in clean_cols:\n",
    "            continue\n",
    "        col = df.columns[clean_cols.index(candidate)]\n",
    "        if any(df[col].apply(checker.is_url)):\n",
    "            return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e6ccb-2634-48ff-928b-54c73579c36b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Column name value counts\n",
    "column_count = defaultdict(lambda: 0)\n",
    "# Key = column name : value = dataframes with that column\n",
    "column_examples = defaultdict(lambda: [])\n",
    "\n",
    "# Files with URL issues\n",
    "files_without_url = []\n",
    "files_with_repeat_urls = []\n",
    "\n",
    "# Counts\n",
    "n_total = 0\n",
    "n_valid = 0\n",
    "\n",
    "verbose = False\n",
    "\n",
    "for fname in tqdm(os.listdir(dirname)):\n",
    "    # Load dataset\n",
    "    ds_id = os.path.splitext(fname)[0]\n",
    "    f_path = os.path.join(dirname, fname)\n",
    "    df = pd.read_csv(f_path, low_memory=False)\n",
    "    n_total += 1\n",
    "\n",
    "    # Any column names with URL or Image?\n",
    "    if not checker.has_url_col(df):\n",
    "        continue\n",
    "    # Extract the column name\n",
    "    url_col = find_url_column(df)\n",
    "\n",
    "    # No URL column found\n",
    "    if not url_col:\n",
    "        if verbose:\n",
    "            print(f\"No url column for {fname} with columns\\n{df.columns}\")\n",
    "        files_without_url.append(fname)\n",
    "        continue\n",
    "\n",
    "    # URL column found!\n",
    "    n_valid += 1\n",
    "    for col in df.columns:\n",
    "        col = col.lower().strip()\n",
    "        column_count[col] += 1\n",
    "        column_examples[col].append(fname)\n",
    "    subdf = df[df[url_col] != \"\"]\n",
    "    if len(subdf) != len(subdf.drop_duplicates(subset=url_col)):\n",
    "        files_with_repeat_urls.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b763999-c70c-45be-91f5-806a7fef5f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"There are {n_valid} valid (of {n_total}) total datasets\")\n",
    "print(f\"Of which {len(files_with_repeat_urls)} have repeated URLs\", end=\"\")\n",
    "print(\" (possibly multiple annotations)\\n\")\n",
    "print(f\"There are {len(column_count)} unique column names:\\n\")\n",
    "\n",
    "# Sort by value in descending order\n",
    "sorted_column_count = dict(\n",
    "    sorted(column_count.items(), key=lambda item: item[1], reverse=True)\n",
    ")\n",
    "for col, count in sorted_column_count.items():\n",
    "    c = col + \" \"\n",
    "    print(f\"{c:.<35s} {count:4d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b478a-bd3d-417f-8e88-f49ea585c812",
   "metadata": {},
   "source": [
    "### Examine each of the columns of interest\n",
    "- Elevation\n",
    "- Depth water\n",
    "- Altitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e1cbe3",
   "metadata": {},
   "source": [
    "#### Elevation\n",
    "**Observations:**\n",
    "- ***Elevation*** values in MOST datasets are negative.\n",
    "- Therefore it is reasonable to assume that ***elevation*** represents the distance of the seafloor from mean sea level.\n",
    "- Source may be onboard sensors or previously recorded seafloor elevation data.\n",
    "- There are a few expections (`val_expections`)\n",
    "    - Positive and zero elevation values dont make sense for underwater photographs\n",
    "    - These values were probably scraped from the dataset webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df384e8f-569d-4ba7-9ac5-94215cf73db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column to find\n",
    "key = \"elevation\"\n",
    "\n",
    "val_expections = {}\n",
    "for i, file in enumerate(column_examples[key]):\n",
    "    df = pd.read_csv(os.path.join(dirname, file))\n",
    "    url_column = find_url_column(df)\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    # Extract info\n",
    "    mean = df[key].mean()\n",
    "    sd = df[key].std()\n",
    "    min_ = df[key].min()\n",
    "    max_ = df[key].max()\n",
    "    url = get_dataset_url(file)\n",
    "    # Show\n",
    "    print(f\"[{i}] Mean: {mean:.2f} ± {sd:.2f} Range: {min_:.2f} to {max_:.2f}\")\n",
    "    # Datasets that defy column value norms\n",
    "    if not ((min_ < 0) and (max_ < 0)):\n",
    "        val_expections[url] = (mean, sd, min_, max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_expections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f68aed3",
   "metadata": {},
   "source": [
    "#### Depth water\n",
    "**Observations:**\n",
    "- ***Depth water*** values in ALL datasets are positive.\n",
    "- Therefore it is reasonable to assume that ***depth water*** represents the absolute distance of the camera vehicle below mean sea level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92694f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column to find\n",
    "key = \"depth water\"\n",
    "\n",
    "val_expections = {}\n",
    "for i, file in enumerate(column_examples[key]):\n",
    "    df = pd.read_csv(os.path.join(dirname, file))\n",
    "    url_column = find_url_column(df)\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    # Extract info\n",
    "    mean = df[key].mean()\n",
    "    sd = df[key].std()\n",
    "    min_ = df[key].min()\n",
    "    max_ = df[key].max()\n",
    "    url = get_dataset_url(file)\n",
    "    # Show\n",
    "    print(f\"[{i}] Mean: {mean:.2f} ± {sd:.2f} Range: {min_:.2f} to {max_:.2f}\")\n",
    "    # Datasets that defy column value norms\n",
    "    if (min_ < 0) and (max_ < 0):\n",
    "        val_expections[url] = (mean, sd, min_, max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5758133",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_expections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41f96e",
   "metadata": {},
   "source": [
    "#### Altitude\n",
    "**Observations:**\n",
    "- ***Altitude*** values in MOST (4 of 5) datasets are positive.\n",
    "- Only exception: values negative (probably same as *elevation*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column to find\n",
    "key = \"altitude\"\n",
    "\n",
    "for i, file in enumerate(column_examples[key]):\n",
    "    df = pd.read_csv(os.path.join(dirname, file))\n",
    "    url_column = find_url_column(df)\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    # Extract info\n",
    "    mean = df[key].mean()\n",
    "    sd = df[key].std()\n",
    "    min_ = df[key].min()\n",
    "    max_ = df[key].max()\n",
    "    url = get_dataset_url(file)\n",
    "    # Show\n",
    "    print(f\"[{i}] Mean: {mean:.2f} ± {sd:.2f} Range: {min_:.2f} to {max_:.2f}\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(-df[\"altitude\"], label=\"altitude\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e54609",
   "metadata": {},
   "source": [
    "## Plot `depth water` and `elevation` values from largest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705a972-2212-47fb-862c-d27cfa8e9298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up largest dataset, containing long cruises\n",
    "df = pd.read_csv(os.path.join(dirname, \"882349.csv\"))\n",
    "print(df.columns)\n",
    "url_column = find_url_column(df)\n",
    "print(\"Sample URL:\", df[url_column].iloc[0])\n",
    "print(\"Dataset Title:\", df[\"dataset_title\"].iloc[0])\n",
    "print(df.doi.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354140a-0c95-42b3-8863-8ceadea95f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(-df[\"Depth water\"], label=\"Depth water\")\n",
    "plt.plot(df[\"Elevation\"], label=\"Elevation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df[\"Depth water\"] + df[\"Elevation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1659fa1",
   "metadata": {},
   "source": [
    "## Datasets with both `depth water` and `elevation` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_set = set(column_examples[\"elevation\"])\n",
    "depth_water_set = set(column_examples[\"depth water\"])\n",
    "intersect = elevation_set.intersection(depth_water_set)\n",
    "\n",
    "print(\"elevation_set :\", len(elevation_set))\n",
    "print(\"depth_water_set :\", len(depth_water_set))\n",
    "print(\"# of files with both:\", len(intersect))\n",
    "\n",
    "for file in intersect:\n",
    "    df = pd.read_csv(os.path.join(dirname, file))\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(-df[\"Depth water\"], label=\"Depth water\")\n",
    "    plt.plot(df[\"Elevation\"], label=\"Elevation\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abef93",
   "metadata": {},
   "source": [
    "## Datasets with both `altitude` and `elevation` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26fea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_set = set(column_examples[\"elevation\"])\n",
    "altitude_set = set(column_examples[\"altitude\"])\n",
    "intersect = elevation_set.intersection(altitude_set)\n",
    "\n",
    "print(\"elevation_set :\", len(elevation_set))\n",
    "print(\"altitude_set :\", len(altitude_set))\n",
    "print(\"# of files with both:\", len(intersect))\n",
    "\n",
    "for file in intersect:\n",
    "    df = pd.read_csv(os.path.join(dirname, file))\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    print(\"All values same:\", all(df.altitude == df.elevation))\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(df[\"altitude\"], label=\"Altitude\")\n",
    "    plt.plot(df[\"elevation\"], label=\"Elevation\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9077788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.altitude != df.elevation][[\"altitude\", \"elevation\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee16e84a",
   "metadata": {},
   "source": [
    "## Datasets with `altitude`, `depth water` and `elevation` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "elevation_set = set(column_examples[\"elevation\"])\n",
    "depth_water_set = set(column_examples[\"depth water\"])\n",
    "altitude_set = set(column_examples[\"altitude\"])\n",
    "intersect = elevation_set.intersection(depth_water_set).intersection(altitude_set)\n",
    "intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496287a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35899785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (ws)",
   "language": "python",
   "name": "ws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
